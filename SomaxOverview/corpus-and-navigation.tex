As previously mentioned, the Somax system generates its improvisation material based on an external set of musical material, the «corpus». This corpus can be constructed from one or multiple MIDI files freely chosen by the user. In contrast to many other generative approaches, the system does not construct a model that eventually is independent of the material that was used to train it. Rather, the model is constructed directly on top of the original data and provides a way to navigate through it in a non-linear manner. One way of seeing this is to consider that some fine-grained aspects of the musical stream are somehow too complex to be modeled, but will be preserved – to a certain extent – when rereading this musical material.

When presented with some MIDI material, the first step is to segment the musical stream into discrete units or «slices», which are vertical (polyphonic) segments of the original midi file and where the duration of a slice is the distance between two note onsets.\footnote{In recorded corpora (or any type of non-quantized MIDI) it is rare for any two notes that are perceived as simultaneous to be exactly simultaneous. Since one goal of Somax is to be able to maintain and reproduce the original timings within slices as recorded, notes with almost simultaneous onsets will still be grouped together in a single slice but with their internal timing offset preserved.} Each slice is analyzed and classified with regards to a number of musical features related to its harmony, individual pitches, dynamics, etc., and these features will serve as the main basis for constructing the navigation model. This process is in a way similar to that of concatenative synthesis, where an audio signal is segmented into meaningful units, analyzed and recombined with respect to the analysis, but  in this case (at least for now) based on MIDI data.

 \begin{figure}[h!]
    \centering        
 	\includegraphics[width=0.95\textwidth]{img/segmentation.png}
    \caption{Constructing a corpus by segmenting midi data into «slices».}
\end{figure}

From the sequence of slices, the navigation model is constructed through the detection of common patterns within the musical material. Or more specifically, the procedure of detecting common patterns is repeated for each feature in the analysis, effectively resulting in a multilayer representation where each layer roughly corresponds to one feature, i.e., one layer for harmony, one for pitch, etc. 

When a musician interacts with the system, a similar process of segmentation and multilayer analysis is computed on the input stream, and at each point in time the result of this process is matched to that of the navigation model, generating activations, or «peaks», at certain points in the corpus where the input corresponds to the model. Each peak corresponds to 
a point in the memory, so the entire set of peaks can effectively be seen linearly as a one-dimensional representation over the corpus' time axis (see figures \ref{fig:peakdecay} and \ref{fig:peakmerge}  below for examples). The peaks in each layer are merged and scaled all according to how the system has been tuned, and finally the output slice is selected based on the distribution of the peaks.

 \begin{figure}[h!]
    \centering        
 	\includegraphics[width=0.95\textwidth]{img/overview.png}
    \caption{An overview of the steps through which the system generates its output at each given point in time.}
\end{figure}

The generated output of this process is an co-improvisation that recombines existing material in a way that's coherent with the sequential logic and statistical properties of the original material while at the same time adapting in real-time to match the input from the musician. One benefit of this procedure compared to many other approaches of statistical machine learning is that the system can generate long improvisations from a small musical corpus, allowing the user detailed control over the style of the output or even specifically compose pieces of material intended to serve as a Somax corpora. Of course, it has to be recognized that this method is also one of the downsides with the model. The process of improvisation is to some extent reduced to a smart cut and pasting of pre-existing material, which is a very simplistic modelling of what improvisation is as a human skill. Still, the output is through the process of attempting to balance the internal logic of the corpus with the external logic of the musician often providing a mix of coherency and unexpectedness in a way that convincingly gives the impression of an active agent in the improvisational process.