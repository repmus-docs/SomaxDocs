\section{Scheduling and the \texttt{Generator} Module}\label{sec:4-generator-evaluator}
While the internal algorithms of the system has been thoroughly described by now, it has not yet been presented in context as a key aspect is missing - how input and output is handled over time, i.e. scheduling. The following sections describe the \texttt{Scheduler} module, which determines how influences and triggers are scheduled to generate actual MIDI/audio output and the modes that the scheduler operate under. Section \ref{sec:4-generator-evaluator-generator} describes the \texttt{Generator} module, which is using the scheduler to generate new corpora offline.

\subsection{Scheduling}\label{sec:4-generator-evaluator-scheduler}
The main role of the \texttt{Scheduler} is to handle triggers to appropriately queue and output slices $\mathcal S^{(\mathcal Y)}_w$ as they unfold over time, similar to a timeline in a DAW but where the events in the timeline are continuously generated by the system itself. The \texttt{Scheduler} has a running tick $t^{(\mathcal Q)}$, a tempo $\zeta^{(\mathcal Q)}$ and a queue of scheduled events $\mathcal E$, where each event has timestamp $t^{(\mathcal Y)}_w$ and a predefined behaviour upon triggering, which depends on the event type. An event will be triggered when its tick $t^{(\mathcal Y)}_w$ is greater than or equal to the scheduler tick $t^{(\mathcal Q)}$. There are currently seven types of scheduled events:

\begin{description}
	\item [\texttt{TempoEvent}:] Sets the tempo of the scheduler to its value when triggered.
	\item [\texttt{MidiEvent}:] Outputs a stored MIDI note on or note off message when triggered.
	\item [\texttt{AudioEvent}:] Outputs an interval $[\tau_\text{start}, \tau_\text{end}]$ (in milliseconds) in the audio file to play over a duration determined by a tempo factor $f_\zeta$, defined as \begin{align}
			f_\zeta = \frac{\zeta^{(\mathcal Y)}_w}{\zeta^{(\mathcal Q)}}
		\end{align}
		where $\zeta^{(\mathcal Y)}_w$ denotes the tempo of the audio event's corresponding slice $\mathcal S^{(\mathcal Y)}_w$.
	\item [\texttt{CorpusEvent}:] Outputs a slice $\mathcal S^{(\mathcal Y)}_w$ when triggered. As we will see in sections \ref{sec:4-generator-evaluator-rt} and \ref{sec:4-generator-evaluator-offline}, this behaviour seems to overlaps with the behaviour of MIDI and audio events, but they are never used in combination.
	\item [\texttt{InfluenceEvent}:] Calls the influence process for a given \texttt{Player} with its stored value.
	\item [\texttt{TriggerEvent}:] Corresponding to an event in the trigger stream $\mathcal Y$, which when triggered calls the generate process. The output of the generate process is sent back to the scheduler and queued, either as a \texttt{CorpusEvent} or as a \texttt{MidiEvent}/\texttt{AudioEvent}, depending on the type of scheduler, as we will see in the following two sections. In practice, this means that all \texttt{MidiEvent}s, \texttt{AudioEvent}s and \texttt{CorpusEvent}s are queued only through a \texttt{TriggerEvent}. 
	
		There are two different ways to add \texttt{TriggerEvent}s to the scheduler, which in turn depends on the scheduler's mode, which may be either \texttt{Automatic} or \texttt{Manual}. The \texttt{Manual} mode means that \texttt{TriggerEvent}s are added manually, which in practice means that they are added by the system after every influence call. This is useful to create a note-by-note interaction between the system and the input. The \texttt{Automatic} mode means that new \texttt{TriggerEvent}s are automatically queued after a duration corresponding to the generated output slice $\mathcal S^{(\mathcal Y)}_w$, i.e. for a trigger $\mathcal Y_i$, a new trigger $\mathcal Y_{i+1}$ is added at $t^{(\mathcal Y)}_{i+1}$ defined as
			\begin{align}
				t^{(\mathcal Y)}_{i+1} = t^{(\mathcal Y)}_i + d^{(\mathcal Y)}_w,
			\end{align}
			where $d^{(\mathcal Y)}_w$ denotes the duration of the generated slice.
			Note that the retriggering uses the time of the trigger $t^{(\mathcal Y)}$ rather than the time of the scheduler $t^{(\mathcal Q)}$ when queueing new triggers to avoid drifting.
\end{description}

In practice, the scheduler is divided into two different classes, the \texttt{RealTime\-Scheduler}, which will be described in section \ref{sec:4-generator-evaluator-rt}, and the \texttt{OfflineScheduler}, which will be described in section \ref{sec:4-generator-evaluator-offline}. As we will see, these two have very little in common apart from the handling of \texttt{TempoEvent}s and \texttt{TriggerEvent}s.

\subsection{Real-time Scheduling}\label{sec:4-generator-evaluator-rt}
The role of the \texttt{RealTimeScheduler} is in many ways similar to the of the audio thread in an audio plugin. It's behaviour is that of a high-priority thread that's continuously polled at a millisecond interval, at each poll $i$ updating its tick so that 
\begin{align}
	t_i^{(\mathcal Q)} = t_{i-1}^{(\mathcal Q)} + \Delta \tau_i \frac {\zeta^{(\mathcal Q)}}{60},
\end{align}
where $\Delta \tau_i$ denotes the number of milliseconds that have passed since the last poll, and triggering any event $w$ whose tick $t^{(\mathcal Y)}_w \ge t^{(\mathcal Q)}_i$.

When the system is used as a real-time framework, the scheduler is based on the \texttt{asyncio} Python module, where influencing and setting parameters, as well as queueing new \texttt{TriggerEvent}s and \texttt{TempoEvent}s, is handled by a different thread corresponding to the ui thread in an audio plugin. The \texttt{asyncio} module is however not truly multithreaded, but rather handles ui calls in-between polling scheduler. These ui calls are blocking the thread and completes its operation before the next poll is called, hence eliminating any risk of tearing. While such a solution would not be acceptable for a real audio thread as the ui calls may delay the audio thread up to a few milliseconds, it's not a problem when handling an event-based stream as the delays incurred by this process generally are too small to be perceivable.\footnote{Do note that this behaviour is a simplification of the scheduling process occurring in each \texttt{Player}. As will be seen in chapter \ref{sec:wireless}, Somax is using an actual multithreaded solution, but the behaviour of each individual thread is still in accordance with the description in this chapter.}

Once a \texttt{TriggerEvent} has generated an output slice $\mathcal S^{(\mathcal Y)}_w$, the real-time scheduler will extract its content as an \texttt{AudioEvent} for audio corpora or as a set of \texttt{MidiEvent}s for MIDI corpora. For MIDI notes $\mathcal N_w$, great care must be taken when determining note ons and note offs, since we according to the slicing procedure would add a single note to multiple slices. In practice, we generate note ons at $t^{(\mathcal Y)}_w$ for any note $n_i \in \mathcal N^{(\text{on})}_w$, where the latter is defined as
	\begin{align}
		\mathcal N^{(\text{on})}_w = \mathcal N^{(\mathcal Y)}_w \setminus \mathcal N^{(\text{from})}_{w-1}
	\end{align}
	and note offs at $t^{(\mathcal W)}_w + n_j\texttt{.duration}$ for any note $n_j \in \mathcal N^{(\text{off})}_w$, where the latter is defined as
	\begin{align}
		\mathcal N^{(\text{off})}_w = \left(
			\mathcal N^{(\mathcal Y)}_w \setminus \mathcal N^{(\text{from})}_w \right)
			\cup
			\left( \mathcal N^{(\text{from})}_{w-1} \setminus \mathcal N^{(\text{to})}_w\right)
	\end{align}
	where
	\begin{align}
		\mathcal N^{(\text{to})}_w = \left\lbrace n \mid n \in \mathcal N^{(\mathcal Y)}_w 
			\colon n\texttt{.onset} < t^{(\mathcal Y)}_w \right\rbrace
	\end{align}
	and
	\begin{align}
		\mathcal N^{(\text{from})}_w = \left\lbrace n \mid n \in \mathcal N^{(\mathcal Y)}_w
			\colon n\texttt{.onset} + n\texttt{.duration} > t^{(\mathcal Y)}_w + d^{(\mathcal Y)}_w \right\rbrace.
	\end{align}

When using the system in real-time, the \texttt{RealTimeScheduler} doesn't handle \texttt{InfluenceEvent}s or \texttt{CorpusEvent}s. The former are handled directly by the ui thread and the latter are converted to \texttt{MidiEvent}s or \texttt{AudioEvent}s.


\subsection{Offline Scheduling}\label{sec:4-generator-evaluator-offline}
The \texttt{OfflineScheduler} is unlike the \texttt{RealTimeScheduler} designed for a single thread, where any operation stems from the scheduler itself while running. It is also not continuously polled, but iterating over all the events $\mathcal E$ in the scheduler in order (where the iterator is being updated after each cycle to allow re-queueing of \texttt{TriggerEvent}s) until the queue is empty. At each step $i$ in the iteration, the tick $t^{(\mathcal Q)}_i$ is updated so that
\begin{align}
	t^{(\mathcal Q)}_i = \operatorname*{min}_{t^{(\mathcal Y)} \in \mathcal E} t^{(\mathcal Y)}
\end{align}
where once again all events $w$ whose tick $t^{(\mathcal Y)}_w \ge t_i^{(\mathcal Q)}$ are triggered in order, sorted by tick position as the first axis and type by the second, to ensure that \texttt{InfluenceEvent}s are triggered before \texttt{TriggerEvent}s, should they occur simultaneously.

Unlike the \texttt{RealTimeScheduler}, the \texttt{OfflineScheduler} will not handle \texttt{Midi\-Event}s or \texttt{AudioEvent}s at all - it will output the slice $\mathcal S^{(\mathcal Y)}_w$ corresponding to the \texttt{CorpusEvent} directly, effectively producing a new \texttt{Corpus}. But since the \texttt{Corpus} class is interchangeable with its MIDI and/or audio data, the generated result could easily be converted to a MIDI/audio file.


\subsection{The \texttt{Generator} Module}\label{sec:4-generator-evaluator-generator}
The \texttt{Generator} is a separate module completely detached from the MaxMSP environment and the real-time system, and is designed around the \texttt{Offline\-Scheduler} to quickly generate new corpora. Similarly to section \ref{sec:4-main-architecture}, the first steps when creating a \texttt{Generator} are to define and initialize the architecture and load a \texttt{Corpus}, which we from here on will call the \textit{source} corpus. The \texttt{Generator} itself is an abstract class where the definition of the architecture is done by extending the class and implementing the \texttt{initialize} function, as can be seen in figure \ref{fig:4-generator-generator}. But as the figure shows, there \texttt{Generator} requires two corpora in the constructor and returns a third corpus from the \texttt{run} function. These three correspond to the three main processes of Somax: a source corpus $\mathcal C$, an influence \textit{corpus} $\mathcal K$ (instead of an influence \textit{stream} as was defined it in \cite{somaxtheory2021}) and an output corpus  $\mathcal O = \left\lbrace \mathcal S^{(\mathcal Y)}_1, \dots \mathcal S^{(\mathcal Y)}_W\right\rbrace$, constructed from the output slices $\mathcal S^{(\mathcal Y)}_w$. In other words, it will build the architecture and source corpus $\mathcal C$ as usual, but it will also build an influence corpus $\mathcal K$ using the same procedure. Each of the slices $\mathcal S^{(\mathcal K)}_v$ of the latter are then queued as \texttt{InfluenceEvent}s in the \texttt{OfflineScheduler} at their corresponding ticks $t^{(\mathcal K)}_v$, together with a \texttt{TempoEvent} constructed from the slice's tempo $\zeta^{(\mathcal K)}_v$ and (if the mode is set to \texttt{Manual}) a \texttt{TriggerEvent}.

When the \texttt{run} function is called, the \texttt{Generator} will iterate over all events in the \texttt{OfflineScheduler} for as long as there are \texttt{InfluenceEvent}s left in the queue and then stop, effectively producing a corpus $\mathcal O$ with the same duration (and hopefully same traits) as the influence corpus $\mathcal K$, using the slices of the source corpus $\mathcal C$.

The \texttt{Generator} module also allows the user to gather statistics about the peaks at each step in the iteration, which can be useful for evaluating the usefulness of the architecture from a performer's perspective.

\begin{figure}
	\begin{lstlisting}
class Generator(ABC):
    def __init__(self, source_corpus: Corpus, influence_corpus: Corpus, 
                 use_optimization: bool, gather_peak_statistics: bool, 
                 name: Optional[str], **kwargs):
        # ...

    def run(self) -> Tuple[Corpus, Optional[PeaksStatistics]]:
        # ...
        
    @abstractmethod
    def initialize(self, **kwargs) -> None:
        pass
	\end{lstlisting}
	\caption{The signature of the constructor and \texttt{run} function as well as the \texttt{initialize} stereotype of the \texttt{Generator} class}
	\label{fig:4-generator-generator}
\end{figure}